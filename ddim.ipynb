{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b83a60-0017-49e0-b7ac-29b32ecfd723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Extended U-Net that can optionally accept a conditioning tensor.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): number of channels for the main input (e.g., 2 for real+imag).\n",
    "        out_channels (int): output channels (e.g., 2 for real+imag).\n",
    "        cond_channels (int): additional channels for conditioning.\n",
    "        features (list): number of feature maps in each encoder layer.\n",
    "        partial_skip (bool): if True, skip the final skip connection.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=2,\n",
    "        out_channels=2,\n",
    "        cond_channels=0,\n",
    "        features=[64, 128, 256],\n",
    "        partial_skip=False\n",
    "    ):\n",
    "        super(UNet, self).__init__()\n",
    "        self.partial_skip = partial_skip\n",
    "        total_in = in_channels + cond_channels\n",
    "\n",
    "        # Encoder blocks.\n",
    "        self.encoders = nn.ModuleList()\n",
    "        prev_channels = total_in\n",
    "        for feature in features:\n",
    "            self.encoders.append(self._block(prev_channels, feature))\n",
    "            prev_channels = feature\n",
    "\n",
    "        # Bottleneck: keep same channel count as the last encoder.\n",
    "        self.bottleneck = self._block(features[-1], features[-1])\n",
    "\n",
    "        # Decoder blocks.\n",
    "        # We design three decoder blocks:\n",
    "        # - Block 0: input 256, output 256.\n",
    "        # - Block 1: input 256, output 128.\n",
    "        # - Block 2: input 128, output 64.\n",
    "        self.decoders = nn.ModuleList([\n",
    "            self._block(features[-1], features[-1]),  # Block 0: 256 -> 256.\n",
    "            self._block(features[-1], features[-2]),  # Block 1: 256 -> 128.\n",
    "            self._block(features[-2], features[0])     # Block 2: 128 -> 64.\n",
    "        ])\n",
    "\n",
    "        # Projection layers to match skip connections:\n",
    "        # For decoder block 1, project skip2 (128 channels) to 256.\n",
    "        self.proj_skip2 = nn.Conv2d(features[1], features[-1], kernel_size=1)  # 128 -> 256.\n",
    "        # For decoder block 2, project skip1 (64 channels) to 128.\n",
    "        self.proj_skip1 = nn.Conv2d(features[0], features[-2], kernel_size=1)   # 64 -> 128.\n",
    "\n",
    "        # Final output layer.\n",
    "        self.final = nn.Conv2d(features[0], out_channels, kernel_size=1)  # from 64 to out_channels.\n",
    "\n",
    "    def _block(self, in_channels, out_channels):\n",
    "        \"\"\"A simple block with two convolutional layers and ReLU activations.\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t=None, cond=None):\n",
    "        \"\"\"\n",
    "        Forward pass with optional conditioning.\n",
    "        If `cond` is provided, it should have shape [B, cond_channels, H, W].\n",
    "        \"\"\"\n",
    "        # 1) Concatenate conditioning if provided.\n",
    "        if cond is not None:\n",
    "            x = torch.cat([x, cond], dim=1)\n",
    "\n",
    "        # 2) Encoder pathway.\n",
    "        skips = []\n",
    "        for encode in self.encoders:\n",
    "            x = encode(x)\n",
    "            skips.append(x)\n",
    "\n",
    "        # 3) Bottleneck.\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        # 4) Decoder with skip connections.\n",
    "        # Assume there are three skip connections: skip1 (64), skip2 (128), skip3 (256).\n",
    "        num_skips = len(skips)  # should be 3.\n",
    "        num_skips_to_use = num_skips if not self.partial_skip else num_skips - 1\n",
    "\n",
    "        for i, decode in enumerate(self.decoders):\n",
    "            if i < num_skips_to_use:\n",
    "                skip = skips[-(i+1)]\n",
    "                if i == 1:\n",
    "                    # For decoder block 1, project skip2 from 128 to 256.\n",
    "                    skip = self.proj_skip2(skip)\n",
    "                if i == 2:\n",
    "                    # For decoder block 2, project skip1 from 64 to 128.\n",
    "                    skip = self.proj_skip1(skip)\n",
    "                x = x + skip\n",
    "            x = decode(x)\n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc8b951-7b64-497b-941a-45ca35b831f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDIM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        unet,\n",
    "        timesteps=1000,\n",
    "        beta_start=1e-4,\n",
    "        beta_end=0.02,\n",
    "        schedule=\"linear\",\n",
    "        device='cpu'\n",
    "    ):\n",
    "        super(DDIM, self).__init__()\n",
    "        self.unet = unet.to(device)\n",
    "        self.timesteps = timesteps\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "        if schedule == \"linear\":\n",
    "            self.betas = torch.linspace(beta_start, beta_end, timesteps).to(device)\n",
    "        elif schedule == \"cosine\":\n",
    "            self.betas = self._cosine_beta_schedule(timesteps).to(device)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown schedule: {schedule}\")\n",
    "\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "        self.alphas_cumprod_prev = torch.cat(\n",
    "            [torch.tensor([1.0], device=device), self.alphas_cumprod[:-1]]\n",
    "        )\n",
    "\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)\n",
    "        self.posterior_variance = (\n",
    "            self.betas * (1.0 - self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)\n",
    "        )\n",
    "\n",
    "    def _cosine_beta_schedule(self, timesteps, warmup_frac=0.02):\n",
    "        \"\"\"\n",
    "        warmup_frac: Fraction of timesteps used as a 'warmup'\n",
    "                    where betas grow very slowly from near-zero.\n",
    "        \"\"\"\n",
    "        # Convert fraction to actual number of warmup steps\n",
    "        warmup_steps = int(timesteps * warmup_frac)\n",
    "\n",
    "        steps = torch.arange(timesteps + 1, dtype=torch.float64, device=self.device)\n",
    "\n",
    "        # Tiny offset (s) for better numerical stability near t=0:\n",
    "        s = 0.008\n",
    "\n",
    "        # Compute the full cosine alphas_cumprod as before\n",
    "        alphas_cumprod_full = torch.cos(((steps / timesteps) + s) / (1 + s) * (torch.pi / 2))**2\n",
    "        alphas_cumprod_full = alphas_cumprod_full / alphas_cumprod_full[0]  # Normalize so alpha(0)=1\n",
    "\n",
    "        # override the first 'warmup_steps' portio nwith a near-linear ramp from 1 down to whatever the original curve\n",
    "        # keeps betas extremely small initially.\n",
    "        if warmup_steps > 0:\n",
    "            # The alpha at the end of warmup\n",
    "            alpha_end_warmup = alphas_cumprod_full[warmup_steps]\n",
    "\n",
    "            warmup_range = torch.linspace(1.0, alpha_end_warmup, warmup_steps + 1, device=self.device)\n",
    "            alphas_cumprod_full[: warmup_steps + 1] = warmup_range\n",
    "\n",
    "        # Convert alphas to betas (1 - alpha_{t} / alpha_{t-1})\n",
    "        betas = 1 - (alphas_cumprod_full[1:] / alphas_cumprod_full[:-1])\n",
    "        return betas.float()\n",
    "\n",
    "\n",
    "    def forward_diffusion(self, x_start, t):\n",
    "        \"\"\"\n",
    "        q(x_t | x_0): Diffuse x_start to x_t at time t by adding noise.\n",
    "        \"\"\"\n",
    "        noise = torch.randn_like(x_start)\n",
    "        sqrt_alpha = self.sqrt_alphas_cumprod[t][:, None, None, None]\n",
    "        sqrt_one_minus_alpha = self.sqrt_one_minus_alphas_cumprod[t][:, None, None, None]\n",
    "        x_t = sqrt_alpha * x_start + sqrt_one_minus_alpha * noise\n",
    "        return x_t, noise\n",
    "    \n",
    "    def forward(self, x, t, cond=None):\n",
    "        \"\"\"\n",
    "        Forward method for training. Predicts the noise from the input x at timestep t.\n",
    "        If conditioning is provided, it passes it along to the U-Net.\n",
    "        \"\"\"\n",
    "        return self.unet(x, t, cond=cond)\n",
    "\n",
    "    def enforce_data_consistency(self, x_pred, x_measured, mask):\n",
    "        \"\"\"\n",
    "        Simplified example of data consistency in the image domain:\n",
    "        merges predicted image and measured image using a binary mask.\n",
    "\n",
    "        For typical undersampled MRI, you'd often do:\n",
    "          1) FFT x_pred  -> kspace_pred\n",
    "          2) Replace known lines in kspace_pred with x_measured (which is k-space)\n",
    "          3) iFFT -> new x_pred\n",
    "        This is just a placeholder approach.\n",
    "        \"\"\"\n",
    "        # Fix the logic: real \"mask\" in image domain might be 1 for known, 0 for unknown\n",
    "        # Combine: known region from x_measured, unknown from x_pred\n",
    "        # Make sure shapes are broadcast-compatible\n",
    "        return x_pred * (1 - mask) + x_measured * mask\n",
    "\n",
    "    def reverse_diffusion(self, x_t, t, x_measured=None, mask=None, eta=0):\n",
    "        \"\"\"\n",
    "        p(x_{t-1} | x_t): reverse step, plus optional data consistency enforcement.\n",
    "\n",
    "        Args:\n",
    "          x_t: shape [B, C, H, W] (image domain) or possibly different dims if coil\n",
    "          t: shape [B], the current time steps\n",
    "          x_measured: optional, same shape as x_t or fewer channels if we do mask merges\n",
    "          mask: optional, binary or float mask\n",
    "          eta: additional noise parameter for DDIM sampling\n",
    "        \"\"\"\n",
    "        cond = None\n",
    "        if x_measured is not None and mask is not None:\n",
    "            # Example: cat measured & mask along channel dim\n",
    "            cond = torch.cat([x_measured, mask], dim=1)\n",
    "\n",
    "        # 1) Predict noise with the U-Net\n",
    "        pred_noise = self.unet(x_t, t, cond=cond)\n",
    "\n",
    "        # 2) Equations for DDIM step\n",
    "        alpha = self.alphas[t][:, None, None, None]\n",
    "        alpha_cumprod = self.alphas_cumprod[t][:, None, None, None]\n",
    "        alpha_cumprod_prev = self.alphas_cumprod_prev[t][:, None, None, None]\n",
    "\n",
    "        pred_x0 = (x_t - torch.sqrt(1 - alpha_cumprod) * pred_noise) / torch.sqrt(alpha_cumprod)\n",
    "        pred_x0 = torch.clamp(pred_x0, -1, 1)\n",
    "\n",
    "        pred_mean = torch.sqrt(alpha_cumprod_prev) * pred_x0 + \\\n",
    "                    torch.sqrt(1 - alpha_cumprod_prev) * pred_noise\n",
    "\n",
    "        # 3) Add optional stochasticity\n",
    "        if eta > 0:\n",
    "            noise = torch.randn_like(x_t)\n",
    "            sigma = eta * torch.sqrt(self.posterior_variance[t])[:, None, None, None]\n",
    "            pred_mean = pred_mean + sigma * noise\n",
    "\n",
    "        # 4) Data consistency\n",
    "        if (x_measured is not None) and (mask is not None):\n",
    "            pred_mean = self.enforce_data_consistency(\n",
    "                x_pred=pred_mean, x_measured=x_measured, mask=mask\n",
    "            )\n",
    "\n",
    "        return pred_mean\n",
    "\n",
    "    def sample(self, shape, x_measured=None, mask=None, eta=0):\n",
    "        \"\"\"\n",
    "        Generate samples using DDIM sampling. We assume x_measured, mask\n",
    "        are the same shape or broadcastable with x_t.\n",
    "\n",
    "        If x_measured is in k-space, you'd need a different DC approach.\n",
    "        \"\"\"\n",
    "        x_t = torch.randn(shape, device=self.device)\n",
    "\n",
    "        for timestep in reversed(range(self.timesteps)):\n",
    "            t_tensor = torch.full((shape[0],), timestep, device=self.device, dtype=torch.long)\n",
    "            x_t = self.reverse_diffusion(\n",
    "                x_t, t_tensor, x_measured=x_measured, mask=mask, eta=eta\n",
    "            )\n",
    "\n",
    "        return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3f9cd-1245-4fe1-944f-c3f8f5ba8c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            folder (str): Path to the folder containing the processed .pt files.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.folder = folder\n",
    "        self.filenames = sorted([f for f in os.listdir(folder) if f.endswith('.pt')])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath = os.path.join(self.folder, self.filenames[idx])\n",
    "        sample = torch.load(filepath)\n",
    "        # If the sample has 4 dimensions, we assume its shape is [kx, ky, complex, coil]\n",
    "        # and we want to convert it to [C, H, W] with C = complex * coil, H = kx, W = ky.\n",
    "        if sample.ndim == 4:\n",
    "            # Permute from [kx, ky, complex, coil] to [complex, coil, kx, ky]\n",
    "            sample = sample.permute(2, 3, 0, 1)\n",
    "            # Reshape to combine the complex and coil dimensions\n",
    "            complex_dim, coil_dim, kx, ky = sample.shape\n",
    "            sample = sample.reshape(complex_dim * coil_dim, kx, ky)\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "def pad_collate_fn(batch, global_max_channels):\n",
    "    \"\"\"\n",
    "    Pads a list of tensors (each of shape [C, H, W]) along the channel, height, \n",
    "    and width dimensions so that each sample is padded (or cropped) to:\n",
    "      - channels: global_max_channels\n",
    "      - height: max height in the batch\n",
    "      - width: max width in the batch\n",
    "    Returns:\n",
    "        torch.Tensor: Batched tensor of shape [batch_size, global_max_channels, max_H, max_W]\n",
    "    \"\"\"\n",
    "    # Compute max height and width among samples in this batch.\n",
    "    max_h = max(sample.shape[1] for sample in batch)\n",
    "    max_w = max(sample.shape[2] for sample in batch)\n",
    "    \n",
    "    padded_batch = []\n",
    "    for sample in batch:\n",
    "        c, h, w = sample.shape\n",
    "        # Pad channels: if sample has fewer than global_max_channels, pad; if more, crop.\n",
    "        if c < global_max_channels:\n",
    "            pad_c = global_max_channels - c\n",
    "            sample = F.pad(sample, (0, 0, 0, 0, 0, pad_c))\n",
    "        elif c > global_max_channels:\n",
    "            sample = sample[:global_max_channels, :, :]\n",
    "        # Pad spatial dimensions\n",
    "        pad_h = max_h - sample.shape[1]\n",
    "        pad_w = max_w - sample.shape[2]\n",
    "        padded_sample = F.pad(sample, (0, pad_w, 0, pad_h))\n",
    "        padded_batch.append(padded_sample)\n",
    "    \n",
    "    return torch.stack(padded_batch)\n",
    "\n",
    "def compute_global_max_channels(data_folder):\n",
    "    \"\"\"\n",
    "    Computes the maximum channel count across all .pt files in data_folder.\n",
    "    Assumes each file, when properly transformed, has shape [C, H, W].\n",
    "    \"\"\"\n",
    "    max_channels = 0\n",
    "    for f in os.listdir(data_folder):\n",
    "        if f.endswith('.pt'):\n",
    "            sample = torch.load(os.path.join(data_folder, f))\n",
    "            # Apply transformation if sample is 4D.\n",
    "            if sample.ndim == 4:\n",
    "                sample = sample.permute(2, 3, 0, 1).reshape(-1, sample.shape[0], sample.shape[1])\n",
    "            max_channels = max(max_channels, sample.shape[0])\n",
    "    return max_channels\n",
    "\n",
    "def get_mri_dataloader(data_folder, batch_size=8, shuffle=True, num_workers=0):\n",
    "    \"\"\"\n",
    "    Creates a DataLoader for the processed MRI data.\n",
    "    \n",
    "    Args:\n",
    "        data_folder (str): Path to the folder containing processed .pt files.\n",
    "        batch_size (int): Batch size.\n",
    "        shuffle (bool): Whether to shuffle the dataset.\n",
    "        num_workers (int): Number of worker processes for data loading.\n",
    "    \n",
    "    Returns:\n",
    "        DataLoader: A PyTorch DataLoader ready to be passed to your model.\n",
    "    \"\"\"\n",
    "    dataset = MRIDataset(data_folder)\n",
    "    global_max_channels = compute_global_max_channels(data_folder)\n",
    "    # Wrap the collate function to automatically pass global_max_channels.\n",
    "    collate_fn = lambda batch: pad_collate_fn(batch, global_max_channels)\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            num_workers=num_workers,\n",
    "                            collate_fn=collate_fn)\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7d759-c497-44f5-bfb7-b5bae6bc9cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_diffusion_model(\n",
    "    data_folder,\n",
    "    num_epochs=10,\n",
    "    lr=1e-4,\n",
    "    timesteps=1000,\n",
    "    batch_size=2,\n",
    "    schedule=\"linear\",\n",
    "    beta_start=1e-4,\n",
    "    beta_end=0.02,\n",
    "    cond_channels=0,\n",
    "    partial_skip=False,\n",
    "    device=None,\n",
    "    checkpoint_dir=None,\n",
    "    final_model_path=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a diffusion model (DDIM + improved U-Net) on processed MRI data.\n",
    "    Data is assumed to be .pt files of shape [C, H, W].\n",
    "\n",
    "    Args:\n",
    "        data_folder (str): Path to folder containing .pt files (e.g. [coil*2, H, W]).\n",
    "        num_epochs (int): Number of training epochs.\n",
    "        lr (float): Learning rate for optimizer.\n",
    "        timesteps (int): Number of diffusion steps (beta schedule length).\n",
    "        batch_size (int): Dataloader batch size.\n",
    "        schedule (str): \"linear\" or \"cosine\".\n",
    "        beta_start (float): Start of beta range for diffusion schedule.\n",
    "        beta_end (float): End of beta range.\n",
    "        cond_channels (int): If > 0, the U-Net can accept additional conditioning channels.\n",
    "        partial_skip (bool): Whether to skip the final skip connection in the U-Net.\n",
    "        device (torch.device): If None, will auto-detect CUDA.\n",
    "        checkpoint_dir (str): Directory to save model checkpoints. If None, checkpoints are not saved.\n",
    "    \"\"\"\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # checkpoint directory\n",
    "    if checkpoint_dir is not None:\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    dataset = MRIDataset(data_folder)\n",
    "    global_max_channels = compute_global_max_channels(data_folder)\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        return pad_collate_fn(batch, global_max_channels)\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    sample = dataset[0]  # expected shape: [C, H, W]\n",
    "    in_channels = sample.shape[0]\n",
    "    print(f\"Detected in_channels: {in_channels}\")\n",
    "    print(\"Sample shape:\", sample.shape)\n",
    "\n",
    "    #  improved U-Net\n",
    "    unet = UNet(\n",
    "        in_channels=global_max_channels,    # input channels (max channels across dataset)\n",
    "        out_channels=global_max_channels,   # output channels\n",
    "        cond_channels=cond_channels,        # optional conditioning channels\n",
    "        features=[64, 128, 256],            # can be adjusted as needed\n",
    "        partial_skip=partial_skip\n",
    "    ).to(device)\n",
    "\n",
    "    #  DDIM\n",
    "    ddim = DDIM(\n",
    "        unet=unet,\n",
    "        timesteps=timesteps,\n",
    "        beta_start=beta_start,\n",
    "        beta_end=beta_end,\n",
    "        schedule=schedule,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    #  loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(ddim.parameters(), lr=lr)\n",
    "\n",
    "    # raining loop\n",
    "    for epoch in range(num_epochs):\n",
    "        ddim.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        # tqdm for a progress bar over the dataloader\n",
    "        for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            batch = batch.to(device)  # batch shape: (B, C, H, W)\n",
    "\n",
    "            # Sample random timesteps for each batch element\n",
    "            t = torch.randint(0, timesteps, (batch.size(0),), device=device).long()\n",
    "\n",
    "            # Forward diffusion: get the noised version and the applied noise\n",
    "            x_t, noise = ddim.forward_diffusion(batch, t)\n",
    "\n",
    "            # Optional: build conditioning if available (here, we set it to None)\n",
    "            cond = None\n",
    "\n",
    "            # Predict the noise from x_t using the DDIM model (i.e., the improved U-Net)\n",
    "            pred_noise = ddim(x_t, t, cond=cond)\n",
    "\n",
    "            # Calculate loss against the ground truth noise\n",
    "            loss = criterion(pred_noise, noise)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]  Loss: {avg_loss:.6f}\")\n",
    "\n",
    "        if checkpoint_dir is not None:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f\"ddim_epoch_{epoch+1}.pt\")\n",
    "            torch.save(ddim.state_dict(), checkpoint_path)\n",
    "            print(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "\n",
    "    if final_model_path is not None:\n",
    "      torch.save(ddim.state_dict(), final_model_path)\n",
    "      print(f\"Final model saved at: {final_model_path}\")\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "    return ddim  # Return the trained diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3ec135de-4536-4e53-9868-748d186e955a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Detected in_channels: 30\n",
      "Sample shape: torch.Size([30, 512, 208])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 3055/3055 [1:03:24<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]  Loss: 0.747562\n",
      "Saved checkpoint: checkpoints/ddim_epoch_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 3055/3055 [1:06:59<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]  Loss: 0.613777\n",
      "Saved checkpoint: checkpoints/ddim_epoch_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 3055/3055 [1:08:39<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10]  Loss: 0.560465\n",
      "Saved checkpoint: checkpoints/ddim_epoch_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 3055/3055 [1:09:11<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10]  Loss: 0.539275\n",
      "Saved checkpoint: checkpoints/ddim_epoch_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 3055/3055 [1:09:15<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10]  Loss: 0.527144\n",
      "Saved checkpoint: checkpoints/ddim_epoch_5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 3055/3055 [1:10:07<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10]  Loss: 0.515371\n",
      "Saved checkpoint: checkpoints/ddim_epoch_6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 3055/3055 [1:12:03<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10]  Loss: 0.508166\n",
      "Saved checkpoint: checkpoints/ddim_epoch_7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 3055/3055 [1:09:55<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10]  Loss: 0.505433\n",
      "Saved checkpoint: checkpoints/ddim_epoch_8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 3055/3055 [1:11:00<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10]  Loss: 0.508539\n",
      "Saved checkpoint: checkpoints/ddim_epoch_9.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 3055/3055 [1:13:45<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10]  Loss: 0.507014\n",
      "Saved checkpoint: checkpoints/ddim_epoch_10.pt\n",
      "Final model saved at: models/1_model.pt\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Path to your folder containing the .pt slice/phase files\n",
    "    data_folder = \"mri-2\"\n",
    "\n",
    "    checkpoint_directory = \"checkpoints\"\n",
    "    final_model_path = \"models/1_model.pt\"\n",
    "\n",
    "    # Train the model with desired hyperparameters\n",
    "    trained_ddim_model = train_diffusion_model(\n",
    "        data_folder=data_folder,\n",
    "        num_epochs=10,\n",
    "        lr=1e-4,\n",
    "        timesteps=1000,\n",
    "        batch_size=2,\n",
    "        schedule=\"linear\",\n",
    "        beta_start=1e-4,\n",
    "        beta_end=0.02,\n",
    "        cond_channels=0,\n",
    "        partial_skip=False,\n",
    "        device=None,               # Will auto-detect GPU if available\n",
    "        checkpoint_dir=checkpoint_directory,\n",
    "        final_model_path=final_model_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c00d4332-47f6-438b-ad7f-5782ae14c506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Detected in_channels: 30\n",
      "Sample shape: torch.Size([30, 512, 208])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 3055/3055 [1:10:06<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]  Loss: 0.770811\n",
      "Saved checkpoint: checkpoints/ddim_epoch_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 3055/3055 [1:10:44<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20]  Loss: 0.645914\n",
      "Saved checkpoint: checkpoints/ddim_epoch_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded. 673/3055 [16:19<55:45,  1.40s/it]  \n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 6/20: 100%|██████████| 3055/3055 [1:10:27<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20]  Loss: 0.554564\n",
      "Saved checkpoint: checkpoints/ddim_epoch_6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 3055/3055 [1:10:58<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20]  Loss: 0.532117\n",
      "Saved checkpoint: checkpoints/ddim_epoch_7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 3055/3055 [1:11:27<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20]  Loss: 0.515193\n",
      "Saved checkpoint: checkpoints/ddim_epoch_8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 3055/3055 [1:11:37<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20]  Loss: 0.504090\n",
      "Saved checkpoint: checkpoints/ddim_epoch_9.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 3055/3055 [1:11:01<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20]  Loss: 0.503113\n",
      "Saved checkpoint: checkpoints/ddim_epoch_10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 3055/3055 [1:11:28<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20]  Loss: 0.510574\n",
      "Saved checkpoint: checkpoints/ddim_epoch_11.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 3055/3055 [1:10:42<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20]  Loss: 0.534209\n",
      "Saved checkpoint: checkpoints/ddim_epoch_12.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 3055/3055 [1:10:35<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20]  Loss: 0.526828\n",
      "Saved checkpoint: checkpoints/ddim_epoch_13.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 3055/3055 [1:10:28<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20]  Loss: 0.522283\n",
      "Saved checkpoint: checkpoints/ddim_epoch_14.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 3055/3055 [1:10:22<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20]  Loss: 0.522597\n",
      "Saved checkpoint: checkpoints/ddim_epoch_15.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 3055/3055 [1:10:37<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20]  Loss: 0.522827\n",
      "Saved checkpoint: checkpoints/ddim_epoch_16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 3055/3055 [1:13:14<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20]  Loss: 0.525293\n",
      "Saved checkpoint: checkpoints/ddim_epoch_17.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 3055/3055 [1:11:03<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20]  Loss: 0.524842\n",
      "Saved checkpoint: checkpoints/ddim_epoch_18.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 3055/3055 [1:10:38<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20]  Loss: 0.523882\n",
      "Saved checkpoint: checkpoints/ddim_epoch_19.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 3055/3055 [1:11:10<00:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20]  Loss: 0.522847\n",
      "Saved checkpoint: checkpoints/ddim_epoch_20.pt\n",
      "Final model saved at: models/2_model.pt\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Path to your folder containing the .pt slice/phase files\n",
    "    data_folder = \"mri-2\"\n",
    "\n",
    "    checkpoint_directory = \"checkpoints\"\n",
    "    final_model_path = \"models/2_model.pt\"\n",
    "\n",
    "    # Train the model with desired hyperparameters\n",
    "    trained_ddim_model = train_diffusion_model(\n",
    "        data_folder=data_folder,\n",
    "        num_epochs=20,\n",
    "        lr=1e-4,\n",
    "        timesteps=1000,\n",
    "        batch_size=4,\n",
    "        schedule=\"cosine\",\n",
    "        beta_start=1e-4,\n",
    "        beta_end=0.02,\n",
    "        cond_channels=0,\n",
    "        partial_skip=False,\n",
    "        device=None,               # Will auto-detect GPU if available\n",
    "        checkpoint_dir=checkpoint_directory,\n",
    "        final_model_path=final_model_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8d216dbe-bba2-43ae-8fe1-e6591753b19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Detected in_channels: 30\n",
      "Sample shape: torch.Size([30, 512, 208])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|██████████| 764/764 [1:10:09<00:00,  5.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15]  Loss: 0.871322\n",
      "Saved checkpoint: checkpoints/ddim_epoch_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|██████████| 764/764 [1:09:00<00:00,  5.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/15]  Loss: 0.750602\n",
      "Saved checkpoint: checkpoints/ddim_epoch_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|██████████| 764/764 [1:13:06<00:00,  5.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/15]  Loss: 0.694001\n",
      "Saved checkpoint: checkpoints/ddim_epoch_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|██████████| 764/764 [1:09:56<00:00,  5.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15]  Loss: 0.657333\n",
      "Saved checkpoint: checkpoints/ddim_epoch_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|██████████| 764/764 [1:10:26<00:00,  5.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/15]  Loss: 0.629889\n",
      "Saved checkpoint: checkpoints/ddim_epoch_5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|██████████| 764/764 [1:10:03<00:00,  5.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/15]  Loss: 0.621281\n",
      "Saved checkpoint: checkpoints/ddim_epoch_6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|██████████| 764/764 [1:09:56<00:00,  5.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/15]  Loss: 0.601611\n",
      "Saved checkpoint: checkpoints/ddim_epoch_7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|██████████| 764/764 [1:09:59<00:00,  5.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/15]  Loss: 0.609662\n",
      "Saved checkpoint: checkpoints/ddim_epoch_8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|██████████| 764/764 [1:09:34<00:00,  5.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/15]  Loss: 0.575513\n",
      "Saved checkpoint: checkpoints/ddim_epoch_9.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100%|██████████| 764/764 [1:09:44<00:00,  5.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15]  Loss: 0.560400\n",
      "Saved checkpoint: checkpoints/ddim_epoch_10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100%|██████████| 764/764 [1:11:25<00:00,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/15]  Loss: 0.555419\n",
      "Saved checkpoint: checkpoints/ddim_epoch_11.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: 100%|██████████| 764/764 [1:10:10<00:00,  5.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/15]  Loss: 0.548409\n",
      "Saved checkpoint: checkpoints/ddim_epoch_12.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: 100%|██████████| 764/764 [1:10:46<00:00,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/15]  Loss: 0.541412\n",
      "Saved checkpoint: checkpoints/ddim_epoch_13.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: 100%|██████████| 764/764 [1:10:20<00:00,  5.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/15]  Loss: 0.538123\n",
      "Saved checkpoint: checkpoints/ddim_epoch_14.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|██████████| 764/764 [1:10:34<00:00,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15]  Loss: 0.533196\n",
      "Saved checkpoint: checkpoints/ddim_epoch_15.pt\n",
      "Final model saved at: models/3_model.pt\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Path to your folder containing the .pt slice/phase files\n",
    "    data_folder = \"mri-2\"\n",
    "\n",
    "    checkpoint_directory = \"checkpoints\"\n",
    "    final_model_path = \"models/3_model.pt\"\n",
    "\n",
    "    # Train the model with desired hyperparameters\n",
    "    trained_ddim_model = train_diffusion_model(\n",
    "        data_folder=data_folder,\n",
    "        num_epochs=15,\n",
    "        lr=1e-4,\n",
    "        timesteps=2000,\n",
    "        batch_size=8,\n",
    "        schedule=\"cosine\",\n",
    "        beta_start=1e-4,\n",
    "        beta_end=0.05,\n",
    "        cond_channels=0,\n",
    "        partial_skip=False,\n",
    "        device=None,               # Will auto-detect GPU if available\n",
    "        checkpoint_dir=checkpoint_directory,\n",
    "        final_model_path=final_model_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6fdcf03f-f495-4be6-a7e6-fb905d5bda7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Detected in_channels: 30\n",
      "Sample shape: torch.Size([30, 512, 208])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 3055/3055 [1:15:35<00:00,  1.48s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]  Loss: 0.957710\n",
      "Saved checkpoint: checkpoints/ddim_epoch_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 3055/3055 [1:13:37<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20]  Loss: 0.923532\n",
      "Saved checkpoint: checkpoints/ddim_epoch_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 3055/3055 [1:11:42<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20]  Loss: 0.911774\n",
      "Saved checkpoint: checkpoints/ddim_epoch_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 3055/3055 [1:11:18<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20]  Loss: 0.910157\n",
      "Saved checkpoint: checkpoints/ddim_epoch_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 3055/3055 [1:11:56<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20]  Loss: 0.908508\n",
      "Saved checkpoint: checkpoints/ddim_epoch_5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 3055/3055 [1:11:20<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20]  Loss: 0.907562\n",
      "Saved checkpoint: checkpoints/ddim_epoch_6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 3055/3055 [1:11:52<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20]  Loss: 0.906750\n",
      "Saved checkpoint: checkpoints/ddim_epoch_7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 3055/3055 [1:11:34<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20]  Loss: 0.906126\n",
      "Saved checkpoint: checkpoints/ddim_epoch_8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 3055/3055 [1:11:59<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20]  Loss: 0.905788\n",
      "Saved checkpoint: checkpoints/ddim_epoch_9.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 3055/3055 [1:11:50<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20]  Loss: 0.905434\n",
      "Saved checkpoint: checkpoints/ddim_epoch_10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 3055/3055 [1:12:05<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20]  Loss: 0.905037\n",
      "Saved checkpoint: checkpoints/ddim_epoch_11.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 3055/3055 [1:11:41<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20]  Loss: 0.904704\n",
      "Saved checkpoint: checkpoints/ddim_epoch_12.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 3055/3055 [1:12:25<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20]  Loss: 0.904558\n",
      "Saved checkpoint: checkpoints/ddim_epoch_13.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.| 1921/3055 [45:13<31:08,  1.65s/it]  \n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 15/20: 100%|██████████| 3055/3055 [1:12:06<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20]  Loss: 0.904044\n",
      "Saved checkpoint: checkpoints/ddim_epoch_15.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 3055/3055 [1:12:16<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20]  Loss: 0.903749\n",
      "Saved checkpoint: checkpoints/ddim_epoch_16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 3055/3055 [1:11:29<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20]  Loss: 0.903602\n",
      "Saved checkpoint: checkpoints/ddim_epoch_17.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 3055/3055 [1:12:03<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20]  Loss: 0.903497\n",
      "Saved checkpoint: checkpoints/ddim_epoch_18.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 3055/3055 [1:11:34<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20]  Loss: 0.903306\n",
      "Saved checkpoint: checkpoints/ddim_epoch_19.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 3055/3055 [1:11:40<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20]  Loss: 0.903343\n",
      "Saved checkpoint: checkpoints/ddim_epoch_20.pt\n",
      "Final model saved at: models/4_model.pt\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Path to your folder containing the .pt slice/phase files\n",
    "    data_folder = \"mri-2\"\n",
    "\n",
    "    checkpoint_directory = \"checkpoints\"\n",
    "    final_model_path = \"models/4_model.pt\"\n",
    "\n",
    "    # Train the model with desired hyperparameters\n",
    "    trained_ddim_model = train_diffusion_model(\n",
    "        data_folder=data_folder,\n",
    "        num_epochs=20,\n",
    "        lr=1e-3,\n",
    "        timesteps=2000,\n",
    "        batch_size=2,\n",
    "        schedule=\"cosine\",\n",
    "        beta_start=1e-4,\n",
    "        beta_end=0.02,\n",
    "        cond_channels=0,\n",
    "        partial_skip=True,\n",
    "        device=None,               # Will auto-detect GPU if available\n",
    "        checkpoint_dir=checkpoint_directory,\n",
    "        final_model_path=final_model_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e797381d-09fd-4825-ac93-b1c5ac315ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Detected in_channels: 30\n",
      "Sample shape: torch.Size([30, 512, 208])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 3055/3055 [1:00:19<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30]  Loss: 0.776185\n",
      "Saved checkpoint: checkpoints/ddim_epoch_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 3055/3055 [1:00:15<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30]  Loss: 0.647565\n",
      "Saved checkpoint: checkpoints/ddim_epoch_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 3055/3055 [1:00:29<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30]  Loss: 0.606750\n",
      "Saved checkpoint: checkpoints/ddim_epoch_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 3055/3055 [1:00:13<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30]  Loss: 0.602419\n",
      "Saved checkpoint: checkpoints/ddim_epoch_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 3055/3055 [1:00:02<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30]  Loss: 0.579372\n",
      "Saved checkpoint: checkpoints/ddim_epoch_5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 3055/3055 [1:00:14<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30]  Loss: 0.557413\n",
      "Saved checkpoint: checkpoints/ddim_epoch_6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 3055/3055 [1:00:28<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30]  Loss: 0.546315\n",
      "Saved checkpoint: checkpoints/ddim_epoch_7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 3055/3055 [1:00:02<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30]  Loss: 0.547810\n",
      "Saved checkpoint: checkpoints/ddim_epoch_8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded. 1766/3055 [34:54<27:23,  1.28s/it] \n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 10/30: 100%|██████████| 3055/3055 [1:00:13<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30]  Loss: 0.538507\n",
      "Saved checkpoint: checkpoints/ddim_epoch_10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 3055/3055 [1:00:22<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30]  Loss: 0.534753\n",
      "Saved checkpoint: checkpoints/ddim_epoch_11.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 3055/3055 [1:00:25<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30]  Loss: 0.533524\n",
      "Saved checkpoint: checkpoints/ddim_epoch_12.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 3055/3055 [1:00:37<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30]  Loss: 0.531911\n",
      "Saved checkpoint: checkpoints/ddim_epoch_13.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 3055/3055 [1:00:24<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30]  Loss: 0.534111\n",
      "Saved checkpoint: checkpoints/ddim_epoch_14.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 3055/3055 [1:00:23<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30]  Loss: 0.532875\n",
      "Saved checkpoint: checkpoints/ddim_epoch_15.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 3055/3055 [1:01:57<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30]  Loss: 0.534947\n",
      "Saved checkpoint: checkpoints/ddim_epoch_16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 3055/3055 [1:02:26<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30]  Loss: 0.530180\n",
      "Saved checkpoint: checkpoints/ddim_epoch_17.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 3055/3055 [1:02:26<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30]  Loss: 0.527698\n",
      "Saved checkpoint: checkpoints/ddim_epoch_18.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 3055/3055 [1:01:30<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30]  Loss: 0.521382\n",
      "Saved checkpoint: checkpoints/ddim_epoch_19.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 3055/3055 [1:01:00<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30]  Loss: 0.522314\n",
      "Saved checkpoint: checkpoints/ddim_epoch_20.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 3055/3055 [1:00:42<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30]  Loss: 0.521428\n",
      "Saved checkpoint: checkpoints/ddim_epoch_21.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 3055/3055 [1:00:52<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30]  Loss: 0.522486\n",
      "Saved checkpoint: checkpoints/ddim_epoch_22.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 3055/3055 [1:04:00<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30]  Loss: 0.521564\n",
      "Saved checkpoint: checkpoints/ddim_epoch_23.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 3055/3055 [1:02:12<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30]  Loss: 0.522340\n",
      "Saved checkpoint: checkpoints/ddim_epoch_24.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 3055/3055 [1:00:43<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30]  Loss: 0.523215\n",
      "Saved checkpoint: checkpoints/ddim_epoch_25.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 3055/3055 [1:00:25<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30]  Loss: 0.520602\n",
      "Saved checkpoint: checkpoints/ddim_epoch_26.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 3055/3055 [1:00:39<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30]  Loss: 0.516041\n",
      "Saved checkpoint: checkpoints/ddim_epoch_27.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 3055/3055 [1:00:47<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30]  Loss: 0.509487\n",
      "Saved checkpoint: checkpoints/ddim_epoch_28.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 3055/3055 [1:00:37<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30]  Loss: 0.508782\n",
      "Saved checkpoint: checkpoints/ddim_epoch_29.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.| 2404/3055 [47:32<15:38,  1.44s/it] \n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Path to your folder containing the .pt slice/phase files\n",
    "    data_folder = \"mri-2\"\n",
    "\n",
    "    checkpoint_directory = \"checkpoints\"\n",
    "    final_model_path = \"models/5_model.pt\"\n",
    "\n",
    "    # Train the model with desired hyperparameters\n",
    "    trained_ddim_model = train_diffusion_model(\n",
    "        data_folder=data_folder,\n",
    "        num_epochs=30,\n",
    "        lr=1e-4,\n",
    "        timesteps=2000,\n",
    "        batch_size=2,\n",
    "        schedule=\"cosine\",\n",
    "        beta_start=1e-4,\n",
    "        beta_end=0.03,\n",
    "        cond_channels=0,\n",
    "        partial_skip=False,\n",
    "        device=None,               # Will auto-detect GPU if available\n",
    "        checkpoint_dir=checkpoint_directory,\n",
    "        final_model_path=final_model_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0079bc9f-d85f-4b55-8be6-3a5320f1a34d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2911f00c-b632-4939-ab30-2141b5abf4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample shape: torch.Size([448, 176, 2, 34])\n",
      "After permute: torch.Size([2, 34, 448, 176])\n",
      "After flattening channels: torch.Size([68, 448, 176])\n",
      "After padding, sample shape: torch.Size([76, 448, 176])\n",
      "k-space output shape: torch.Size([1, 76, 448, 176])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.fft\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hyperparameters and device setup\n",
    "global_max_channels = 76        \n",
    "timesteps = 1000\n",
    "schedule = \"cosine\"\n",
    "beta_start = 1e-4\n",
    "beta_end = 0.02\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assume UNet and DDIM classes have been defined/imported appropriately.\n",
    "# Instantiate the model with the same configuration as during training.\n",
    "unet = UNet(\n",
    "    in_channels=global_max_channels,    # should match the global_max_channels used in training\n",
    "    out_channels=global_max_channels,\n",
    "    features=[64, 128, 256],\n",
    ")\n",
    "ddim = DDIM(\n",
    "    unet=unet,\n",
    "    timesteps=timesteps,\n",
    "    beta_start=beta_start,\n",
    "    beta_end=beta_end,\n",
    "    schedule=schedule,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Load the saved state dictionary\n",
    "state_dict = torch.load(\"models/3_model.pt\", map_location=device)\n",
    "ddim.load_state_dict(state_dict)\n",
    "ddim.to(device)\n",
    "ddim.eval()\n",
    "\n",
    "# --- Load a sample input ---\n",
    "# shape [kx, ky, 2, coil]\n",
    "sample = torch.load(\"mri-2/fs_0078_1_5T_slice0_phase12.pt\", map_location=device)\n",
    "print(\"Original sample shape:\", sample.shape)  # e.g. [kx, ky, 2, coil]\n",
    "\n",
    "# Permute from [kx, ky, 2, coil] to [2, coil, kx, ky]\n",
    "sample = sample.permute(2, 3, 0, 1)\n",
    "print(\"After permute:\", sample.shape)  # Expected: [2, coil, kx, ky]\n",
    "\n",
    "# Flatten the first two dimensions to get [C, kx, ky] with C = 2*coil.\n",
    "sample = sample.reshape(-1, sample.shape[-2], sample.shape[-1])\n",
    "print(\"After flattening channels:\", sample.shape)  # e.g. [68, kx, ky]\n",
    "\n",
    "# Pad (or crop) the channel dimension to match global_max_channels.\n",
    "if sample.shape[0] < global_max_channels:\n",
    "    pad_channels = global_max_channels - sample.shape[0]\n",
    "    sample = F.pad(sample, (0, 0, 0, 0, 0, pad_channels))\n",
    "    print(\"After padding, sample shape:\", sample.shape)\n",
    "elif sample.shape[0] > global_max_channels:\n",
    "    sample = sample[:global_max_channels, :, :]\n",
    "    print(\"After cropping, sample shape:\", sample.shape)\n",
    "\n",
    "# Add a batch dimension: now [1, C, H, W]\n",
    "sample = sample.unsqueeze(0).to(device)\n",
    "\n",
    "# --- Run the model ---\n",
    "with torch.no_grad():\n",
    "    t = torch.randint(0, timesteps, (sample.size(0),), device=device).long()\n",
    "    kspace_output = ddim(sample, t=t, cond=None)\n",
    "    # kspace_output should have shape [B, global_max_channels, H, W]\n",
    "print(\"k-space output shape:\", kspace_output.shape)\n",
    "\n",
    "# --- Convert k-space output to image domain ---\n",
    "B, C, H, W = kspace_output.shape\n",
    "if C % 2 != 0:\n",
    "    raise ValueError(\"Expected an even number of channels (coil*2).\")\n",
    "num_coils = C // 2\n",
    "\n",
    "# Reshape to separate coil and complex dimensions: [B, num_coils, 2, H, W]\n",
    "kspace_reshaped = kspace_output.view(B, num_coils, 2, H, W)\n",
    "# Convert to a complex tensor: first channel is real, second is imaginary.\n",
    "kspace_complex = torch.complex(kspace_reshaped[:, :, 0, :, :],\n",
    "                                kspace_reshaped[:, :, 1, :, :])\n",
    "# kspace_complex now has shape: [B, num_coils, H, W]\n",
    "\n",
    "# Optionally apply ifftshift to center k-space\n",
    "if True:\n",
    "    kspace_complex = torch.fft.ifftshift(kspace_complex, dim=(-2, -1))\n",
    "\n",
    "# Perform a 2D inverse FFT (with orthogonal normalization)\n",
    "image_coils = torch.fft.ifft2(kspace_complex, norm='ortho')\n",
    "\n",
    "# Optionally apply fftshift to recenter the image\n",
    "if True:\n",
    "    image_coils = torch.fft.fftshift(image_coils, dim=(-2, -1))\n",
    "\n",
    "# Compute the magnitude for each coil image\n",
    "coil_magnitudes = torch.abs(image_coils)\n",
    "\n",
    "# Combine coil images using the Sum-Of-Squares (SOS) method: result [B, H, W]\n",
    "reconstructed_image = torch.sqrt(torch.sum(coil_magnitudes ** 2, dim=1))\n",
    "\n",
    "# --- Rescale intensity via min–max normalization ---\n",
    "img_min = reconstructed_image.min()\n",
    "img_max = reconstructed_image.max()\n",
    "reconstructed_image = (reconstructed_image - img_min) / (img_max - img_min + 1e-8)\n",
    "\n",
    "# For visualization, take the first image in the batch\n",
    "img_to_show = reconstructed_image[0].cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img_to_show, cmap='gray')\n",
    "plt.title(\"Reconstructed Image (IFFT of k-space Output) with Rescaled Intensity\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04efa21b-3995-4373-a38b-afe6ffea0d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e9b4d-75c5-4f6f-9bb8-599b08a505ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2c8f3-9fe5-4252-8b51-2a87b5f76e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ed46ab-c2be-40e7-92bf-99fe9a5eb703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
